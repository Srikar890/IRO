{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUtUWV9eXZ4l",
        "outputId": "a66d563f-0f3f-45ec-c235-424c3b6cd58d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define document\n",
        "doc_1 = \"Every year Maha Shivratri is celebrated with a lot of pomp and grandeur. It is considered to be a very special time of the year since millions of people celebrate this momentous occasion with a lot of fervour and glee.\"\n",
        "doc_2 = \"Lord Shiva devotees celebrate this occasion with a lot of grandness. It is accompanied by folk dances,songs, prayers, chants, mantras etc. This year,the beautiful occasion of Maha Shivratri will be celebrated on February 18.\"\n",
        "doc_3 = \"People keep a fast on this Maha shivratri, stay awake at night and pray to the lord for blessings,happiness, hope and prosperity. This festival holds a lot of significance and is considered to be one of the most important festivals in India\"\n",
        "doc_4 = \"The festival of Maha Shivratri will be celebrated on February 18 and is a very auspicious festival. This Hindu festival celebrates the power of Lord Shiva. Lord Shiva protects his devotees from negative and evil spirits. He is the epitome of powerful and auspicious energy\"\n",
        "documents = [doc_1,doc_2,doc_3,doc_4]"
      ],
      "metadata": {
        "id": "lPtLFKJ0XkRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenize and lemmatize a document using the word_tokenize and WordNetLemmatizer from the nltk library.**\n",
        "  \n",
        "    Args:\n",
        "        document (str): The document to lemmatize.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of lemmatized tokens."
      ],
      "metadata": {
        "id": "OxqmMIdSiV5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the documents\n",
        "tokenized_docs = []\n",
        "for doc in documents:\n",
        "    tokens = nltk.word_tokenize(doc)\n",
        "    tokenized_docs.append(tokens)\n"
      ],
      "metadata": {
        "id": "xxLhP68kY9Ke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the vocabulary\n",
        "vocab = set()\n",
        "for tokens in tokenized_docs:\n",
        "    for word in tokens:\n",
        "        vocab.add(word)"
      ],
      "metadata": {
        "id": "TYP72IKVZFV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmatize the tokens\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_docs = []\n",
        "for tokens in tokenized_docs:\n",
        "    lemmatized_tokens = []\n",
        "    for token in tokens:\n",
        "        lemmatized_token = lemmatizer.lemmatize(token)\n",
        "        lemmatized_tokens.append(lemmatized_token)\n",
        "    lemmatized_docs.append(lemmatized_tokens)"
      ],
      "metadata": {
        "id": "qyOFArL-ZWPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the term frequency for each document\n",
        "tf = []\n",
        "for doc in lemmatized_docs:\n",
        "    doc_tf = {}\n",
        "    for word in doc:\n",
        "        if word in doc_tf:\n",
        "            doc_tf[word] += 1\n",
        "        else:\n",
        "            doc_tf[word] = 1\n",
        "    tf.append(doc_tf)"
      ],
      "metadata": {
        "id": "cMxv3HPGZaBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the inverse document frequency for each term in the vocabulary\n",
        "idf = {}\n",
        "N = len(documents)\n",
        "epsilon = 1e-6 \n",
        "for word in vocab:\n",
        "    n = sum([1 for doc in lemmatized_docs if word in doc])\n",
        "    idf[word] = math.log(N/(n + epsilon))\n",
        "    "
      ],
      "metadata": {
        "id": "4SBFXwVEZnfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the tf-idf for each document\n",
        "tf_idf = []\n",
        "for i in range(N):\n",
        "    doc_tf_idf = {}\n",
        "    doc_tf = tf[i]\n",
        "    for word in doc_tf:\n",
        "        if word in idf:\n",
        "            doc_tf_idf[word] = doc_tf[word] * idf[word]\n",
        "    tf_idf.append(doc_tf_idf)"
      ],
      "metadata": {
        "id": "gEEf0AddcGAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ask the user for a query\n",
        "query = input(\"Every year Maha\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7M9u72oaWG2",
        "outputId": "e4cbc448-430d-408a-99ba-fb43e65f8126"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Every year MahaEvery year Maha\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the tf-idf for the query\n",
        "query_tf_idf = {}\n",
        "query_words = query.split()\n",
        "for word in query_words:\n",
        "    if word in query_tf_idf:\n",
        "        query_tf_idf[word] += 1\n",
        "    else:\n",
        "        query_tf_idf[word] = 1\n",
        "for word in query_tf_idf:\n",
        "    if word in idf:\n",
        "        query_tf_idf[word] *= idf[word]"
      ],
      "metadata": {
        "id": "Wfp8qSoGaWEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculate the cosine similarity between two documents.**\n",
        "\n",
        "    Args:\n",
        "        doc1 (dict): The first document represented as a dictionary of word frequencies.\n",
        "        doc2 (dict): The second document represented as a dictionary of word frequencies.\n",
        "\n",
        "    Returns:\n",
        "        float: The cosine similarity between the two documents."
      ],
      "metadata": {
        "id": "F7hHSSr8inMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to calculate the cosine similarity between document and query\n",
        "def cosine_similarity(set1, set2):\n",
        "    dot = sum([set1[word] * set2[word] for word in set1 if word in set2])\n",
        "    norm_doc = math.sqrt(sum([set1[word]**2 for word in set1]))\n",
        "    norm_query = math.sqrt(sum([set2[word]**2 for word in set2]))\n",
        "    return dot/ (norm_doc * norm_query)"
      ],
      "metadata": {
        "id": "KMqgU2f_Zq1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculate the Jaccard similarity between two sets of tokens.**\n",
        "\n",
        "    Args:\n",
        "        documents (set): A set of tokens representing a document.\n",
        "        query (set): A set of tokens representing a query.\n",
        "\n",
        "    Returns:\n",
        "        float: The Jaccard similarity between the two sets of tokens."
      ],
      "metadata": {
        "id": "gmJNLfCYix4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to calculate the Jaccard similarity between two documents\n",
        "def jaccard_similarity(set1, set2):\n",
        "    intersection = set1.intersection(set2)\n",
        "    union = set1.union(set2)\n",
        "    return len(intersection) / len(union)"
      ],
      "metadata": {
        "id": "xLeQVHepbNkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the cosine similarity between the query and each document\n",
        "cosine_similarities = []\n",
        "for i in range(N):\n",
        "    cosine_similarities.append(cosine_similarity(query_tf_idf, tf_idf[i]))\n",
        "\n",
        "# Calculate the Jaccard similarity between the query and each document\n",
        "jaccard_similarities = []\n",
        "for i in range(N):\n",
        "    jaccard_similarities.append(jaccard_similarity(set(query_words), set(documents[i].split())))"
      ],
      "metadata": {
        "id": "yF5ATLazbzGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort the cosine similarities in descending order and print the top two documents\n",
        "cosine_similarities_sorted = sorted(range(len(cosine_similarities)), key=lambda i: cosine_similarities[i], reverse=True)\n",
        "print(\"Top two documents by cosine similarity:\")\n",
        "for i in range(2):\n",
        "    print(\"Document {}: {}\".format(cosine_similarities_sorted[i]+1, cosine_similarities[cosine_similarities_sorted[i]]))\n",
        "\n",
        "# Sort the Jaccard similarities in descending order and print the top two documents\n",
        "jaccard_similarities_sorted = sorted(range(len(jaccard_similarities)), key=lambda i: jaccard_similarities[i], reverse=True)\n",
        "print(\"Top two documents by Jaccard similarity:\")\n",
        "for i in range(2):\n",
        "    print(\"Document {}: {}\".format(jaccard_similarities_sorted[i]+1, jaccard_similarities[jaccard_similarities_sorted[i]]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JSVFYc3eYTr",
        "outputId": "57a9b929-4fb5-4e91-cd2d-2dd7e86e2ee1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top two documents by cosine similarity:\n",
            "Document 1: 0.358905805925845\n",
            "Document 2: 0.05632862668745375\n",
            "Top two documents by Jaccard similarity:\n",
            "Document 1: 0.1\n",
            "Document 2: 0.029411764705882353\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "https://docs.google.com/document/d/1yUV7N1DPthCIoB6lohisZdiPsArdza4iVWAj7l9MYwA/edit?usp=drivesdk"
      ],
      "metadata": {
        "id": "8L1aEf4vblD1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}